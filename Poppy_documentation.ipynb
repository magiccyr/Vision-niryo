{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation du Projet Poppy Torso\n",
    "\n",
    "Ce document décrit les fonctionnalités et le code d'un projet utilisant le robot Poppy Torso. Le projet inclut des séquences de mouvement, de la détection d'objets, et des interactions vocales via des modèles d'IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Prérequis**\n",
    "- **Matériel** :\n",
    "  - Robot Poppy Torso (ou simulateur V-REP).\n",
    "  - Caméra USB (pour la détection de couleurs).\n",
    "  - Microphone (pour les commandes vocales).\n",
    "- **Logiciel** :\n",
    "  - Environnement Python 3.8+.\n",
    "  - Librairies : `pypot`, `numpy`, `opencv-python`, `speech_recognition`, `gTTS`, `transformers`, `openai`, etc.\n",
    "  - Simulateur V-REP (si utilisé).\n",
    "  - Clés API pour OpenAI et Mistral (pour les assistants vocaux).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Fonctionnalités principales**\n",
    "### **2.1 Séquence de salutation**\n",
    "- **Description** : Le robot lève les bras, salue, et incline son torse.\n",
    "- **Fichier** : `document2.ipynb` (première cellule).\n",
    "- **Fonctions clés** :\n",
    "  - `smooth_move()` : Interpolation de mouvement avec une courbe de Bézier.\n",
    "  - `salutation_sequence()` : Orchestre les étapes de la salutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypot.creatures import PoppyTorso\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Initialisation du robot Poppy Torso\n",
    "robot = PoppyTorso(simulator=\"vrep\")\n",
    "\n",
    "# Définition des moteurs principaux\n",
    "motors = {\n",
    "    \"torso\": robot.bust_y,\n",
    "    \"left_shoulder\": robot.l_shoulder_y,\n",
    "    \"right_shoulder\": robot.r_shoulder_y,\n",
    "    \"left_arm\": robot.l_arm_z,\n",
    "    \"right_arm\": robot.r_arm_z\n",
    "}\n",
    "\n",
    "# Fonction pour interpoler en douceur les mouvements avec une courbe de Bézier\n",
    "def smooth_move(motor, start, end, duration=2, steps=50):\n",
    "    t = np.linspace(0, 1, steps)\n",
    "    bezier = (1 - t) ** 2 * start + 2 * (1 - t) * t * ((start + end) / 2) + t ** 2 * end\n",
    "    for pos in bezier:\n",
    "        motor.goal_position = pos\n",
    "        time.sleep(duration / steps)\n",
    "\n",
    "# Réinitialisation du robot en position neutre\n",
    "def reset_position():\n",
    "    for motor in motors.values():\n",
    "        motor.goal_position = 0\n",
    "    time.sleep(1)\n",
    "\n",
    "# Séquence de salutation et inclinaison\n",
    "def salutation_sequence():\n",
    "    print(\"Début de la salutation...\")\n",
    "\n",
    "    # Lever les bras\n",
    "    smooth_move(motors[\"left_shoulder\"], 0, 40, duration=1)\n",
    "    smooth_move(motors[\"right_shoulder\"], 0, -40, duration=1)\n",
    "\n",
    "    # Saluer avec un bras\n",
    "    smooth_move(motors[\"left_arm\"], 0, 30, duration=1)\n",
    "    smooth_move(motors[\"left_arm\"], 30, 0, duration=1)\n",
    "\n",
    "    # Inclinaison du torse\n",
    "    smooth_move(motors[\"torso\"], 0, 20, duration=1.5)\n",
    "    smooth_move(motors[\"torso\"], 20, -10, duration=1)\n",
    "    smooth_move(motors[\"torso\"], -10, 0, duration=1)\n",
    "\n",
    "    # Repose les bras\n",
    "    smooth_move(motors[\"left_shoulder\"], 40, 0, duration=1)\n",
    "    smooth_move(motors[\"right_shoulder\"], -40, 0, duration=1)\n",
    "\n",
    "    print(\"Salutation terminée.\")\n",
    "\n",
    "# Lancer le mouvement\n",
    "reset_position()\n",
    "salutation_sequence()\n",
    "reset_position()\n",
    "\n",
    "print(\"Fin du programme.\")\n",
    "robot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Mouvement \"Dab\"**\n",
    "- **Description** : Le robot effectue un mouvement de dab.\n",
    "- **Fonctions clés** :\n",
    "  - `dab_move()` : Contrôle les épaules, coudes, et tête pour réaliser le dab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypot.creatures import PoppyTorso\n",
    "import time\n",
    "import numpy as np\n",
    "robot = PoppyTorso(simulator='vrep')\n",
    "# Définition des moteurs principaux\n",
    "motors = {\n",
    "    \"head_z\": robot.head_z,\n",
    "    \"head_y\": robot.head_y,\n",
    "    \"torso\": robot.bust_y,\n",
    "    \"left_arm\": robot.l_arm_z,\n",
    "    \"right_arm\": robot.r_arm_z,\n",
    "    \"right_elbow\": robot.r_elbow_y,\n",
    "    \"left_elbow\": robot.l_elbow_y,\n",
    "    \"left_shoulder_y\": robot.l_shoulder_y,\n",
    "    \"right_shoulder_y\": robot.r_shoulder_y,\n",
    "    \"left_shoulder_x\" : robot.l_shoulder_x,\n",
    "    \"right_shoulder_x\": robot.r_shoulder_x\n",
    "}\n",
    "# Fonction de déplacement en douceur\n",
    "def smooth_move (motor,target_position,duration=1.5):\n",
    "    initial_position= motor.present_position\n",
    "    duration=duration/2\n",
    "    steps =50\n",
    "    for i in range (steps):\n",
    "        motor.goal_position= initial_position+ (target_position-initial_position)*(i/steps)\n",
    "        time.sleep(duration/steps)\n",
    "        \n",
    "# Réinitialisation du robot en position neutre\n",
    "def reset_position():\n",
    "    for motor in motors.values():\n",
    "        smooth_move(motor,0,1.5)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# Fonction de faire le dab\n",
    "def dab_move():\n",
    "    print(\"Exécution du dab\")\n",
    "    \n",
    "    #lever le bras droit vers le haut \n",
    "    smooth_move(motors[\"right_arm\"],-90,duration=1.5)\n",
    "    \n",
    "    \n",
    "    #lever l'épaule droite\n",
    "    smooth_move(motors[\"left_shoulder_y\"],-90,duration=1.5)\n",
    "    smooth_move(motors[\"left_elbow\"],-30,duration=1.5)\n",
    "\n",
    "    \n",
    "    #lever l'épaule gauche\n",
    "    smooth_move(motors[\"right_shoulder_y\"],-90,duration=1.5)\n",
    "    \n",
    "    \n",
    "    #Incliner la tête vers le bas\n",
    "    smooth_move(motors[\"head_z\"],30,duration=1)\n",
    "    smooth_move(motors[\"head_y\"],30,duration=1)\n",
    "\n",
    "    # tendre le bras\n",
    "    smooth_move(motors[\"right_elbow\"],90,duration=1.5)\n",
    "    smooth_move(motors[\"right_shoulder_x\"],-90,duration=1.5)\n",
    "\n",
    "    #baisser le bras gauche en diagonale\n",
    "    smooth_move(motors[\"left_arm\"],-90,duration=1.5)\n",
    "    #Inciner le torse \n",
    "    smooth_move(motors[\"torso\"],15,duration=1)\n",
    "    \n",
    "    print(\"dab éffectué\")\n",
    "    \n",
    "    #maintenir la position pendant 5 secondes\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #retour à la position normale\n",
    "    reset_position()\n",
    "    \n",
    "#lancer le mouvement\n",
    "reset_position()\n",
    "dab_move()\n",
    "reset_position()\n",
    "\n",
    "print(\"Fin du programme\")\n",
    "robot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déplacement d'un objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypot.creatures import PoppyTorso\n",
    "import time\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "robot = PoppyTorso(simulator=\"vrep\")\n",
    "\n",
    "# Définition des moteurs principaux\n",
    "motors = {\n",
    "    \"head_z\": robot.head_z,\n",
    "    \"head_y\": robot.head_y,\n",
    "    \"torso\": robot.bust_y,\n",
    "    \"left_shoulder_y\": robot.l_shoulder_y,\n",
    "    \"right_shoulder_y\": robot.r_shoulder_y,\n",
    "    \"left_shoulder_x\" : robot.l_shoulder_x,\n",
    "    \"right_shoulder_x\": robot.r_shoulder_x,\n",
    "    \"left_arm\": robot.l_arm_z,\n",
    "    \"right_arm\": robot.r_arm_z,\n",
    "    \"right_elbow\": robot.r_elbow_y,\n",
    "    \"left_elbow\": robot.l_elbow_y,\n",
    "    \"abs_z\": robot.abs_z\n",
    "}\n",
    "for i in motors.values():\n",
    "    i.speed_limit =20\n",
    "# Réinitialisation du robot en position neutre\n",
    "def reset_position():\n",
    "    for motor in motors.values():\n",
    "        motor.goal_position=0\n",
    "    time.sleep(1)\n",
    "# fonction de ramassage d'objet\n",
    "\n",
    "def soulever():\n",
    "    print(\"début du levage\")\n",
    "    #position initiale bras ouverts\n",
    "    T1=threading.Thread(target=smooth_move,args=(motors[\"left_arm\"],30,1.5))\n",
    "    T2=threading.Thread(target=smooth_move,args=(motors[\"right_arm\"],-30,1.5))\n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    time.sleep(2)\n",
    "    #descente des bras pour attraper l'objet\n",
    "    T1=threading.Thread(target=smooth_move,args=(motors[\"left_shoulder_y\"],15,1.5))\n",
    "    T2=threading.Thread(target=smooth_move,args=(motors[\"right_shoulder_y\"],15,1.5))\n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #fermeture des bras(prise)\n",
    "    T1=threading.Thread(target=smooth_move,args=(motors[\"left_arm\"],-20,1.5))\n",
    "    T2=threading.Thread(target=smooth_move,args=(motors[\"right_arm\"],20,1.5))\n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #remontée de l'objet\n",
    "    T1=threading.Thread(target=smooth_move,args=(motors[\"left_shoulder_y\"],-45,1.5))\n",
    "    T2=threading.Thread(target=smooth_move,args=(motors[\"right_shoulder_y\"],-45,1.5))\n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    time.sleep(2)\n",
    "    time.sleep(2)\n",
    "        \n",
    "    print('objet soulevé avec succès')\n",
    "    \n",
    "def deplacer():\n",
    "    print(\"début du déplacement de l'objet\")\n",
    "    smooth_move(motors[\"abs_z\"],90,duration=1.5)\n",
    "    time.sleep(2)\n",
    "    \n",
    "def deposer():\n",
    "    print(\"début du dépot de l'objet\")\n",
    "    T1=threading.Thread(target=smooth_move,args=(motors[\"left_shoulder_y\"],-10,1.5))\n",
    "    T2=threading.Thread(target=smooth_move,args=(motors[\"right_shoulder_y\"],-10,1.5))\n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    time.sleep(2)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    T1=threading.Thread(target=smooth_move,args=(motors[\"left_arm\"],0,1.5))\n",
    "    T2=threading.Thread(target=smooth_move,args=(motors[\"right_arm\"],0,1.5))\n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    time.sleep(2)\n",
    "        \n",
    "#lancer le mouvement\n",
    "reset_position()\n",
    "soulever()\n",
    "deplacer()\n",
    "deposer()\n",
    "reset_position()\n",
    "\n",
    "robot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Tri d'objets par couleur**\n",
    "- **Description** : Détection de couleur via caméra et déplacement d'objets.\n",
    "- **Fonctions clés** :\n",
    "  - `detecter_couleur()` : Analyse la région centrale de l'image en HSV.\n",
    "  - `soulever()`, `deplacer()`, `deposer()` : Contrôlent les bras pour manipuler les objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pypot.creatures import PoppyTorso\n",
    "import time\n",
    "\n",
    "# ===============================\n",
    "# 1. Initialisation du robot\n",
    "# ===============================\n",
    "poppy = PoppyTorso(simulator='vrep')\n",
    "print(\"Moteurs disponibles :\", [m.name for m in poppy.motors])\n",
    "\n",
    "# ===============================\n",
    "# 2. Définition des positions des bacs\n",
    "# ===============================\n",
    "POSITIONS = {\n",
    "    \"rouge\": {  # Bac 1 (72°)\n",
    "        \"abs_z\": 72, \"r_shoulder_y\": -30, \"r_shoulder_x\": 15, \"r_elbow_y\": -20,\n",
    "    },\n",
    "    \"vert\": {  # Bac 2 (144°)\n",
    "        \"abs_z\": 144, \"r_shoulder_y\": -15, \"r_shoulder_x\": 10, \"r_elbow_y\": -10,\n",
    "    },\n",
    "    \"bleu\": {  # Bac 3 (216°)\n",
    "        \"abs_z\": 216, \"r_shoulder_y\": 10, \"r_shoulder_x\": -10, \"r_elbow_y\": 5,\n",
    "    },\n",
    "    \"jaune\": {  # Bac 4 (288°)\n",
    "        \"abs_z\": 288, \"r_shoulder_y\": 20, \"r_shoulder_x\": -15, \"r_elbow_y\": 10,\n",
    "    },\n",
    "    \"violet\": {  # Bac 5 (360° ou 0°)\n",
    "        \"abs_z\": 0, \"r_shoulder_y\": 25, \"r_shoulder_x\": -20, \"r_elbow_y\": 15,\n",
    "    },\n",
    "}\n",
    "\n",
    "# 3. Définition des plages de couleurs en HSV\n",
    "COULEURS = {\n",
    "    \"rouge\": [(0, 120, 70), (10, 255, 255)],\n",
    "    \"vert\":  [(40, 40, 40), (80, 255, 255)],\n",
    "    \"bleu\":  [(100, 150, 0), (140, 255, 255)],\n",
    "    \"jaune\": [(20, 100, 100), (30, 255, 255)],\n",
    "    \"violet\": [(130, 50, 50), (160, 255, 255)],\n",
    "}\n",
    "\n",
    "# 4. Initialisation de la caméra\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detecter_couleur(image):\n",
    "    \"\"\"\n",
    "    Détecte la couleur dominante dans la région centrale de l'image.\n",
    "    Retourne une des clés de COULEURS si la détection est positive, sinon \"inconnu\".\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hauteur, largeur, _ = image.shape\n",
    "    x_start, x_end = largeur // 3, 2 * largeur // 3\n",
    "    y_start, y_end = hauteur // 3, 2 * hauteur // 3\n",
    "    roi = hsv[y_start:y_end, x_start:x_end]\n",
    "\n",
    "    for couleur, (borne_basse, borne_haute) in COULEURS.items():\n",
    "        masque = cv2.inRange(roi, np.array(borne_basse), np.array(borne_haute))\n",
    "        if cv2.countNonZero(masque) > 500:\n",
    "            return couleur\n",
    "    return \"inconnu\"\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    timeout = 10  # Durée maximale de détection en secondes\n",
    "    couleur_trouvee = None\n",
    "\n",
    "    # Boucle de détection pendant 10 secondes max\n",
    "    while (time.time() - start_time) < timeout:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Erreur de capture vidéo.\")\n",
    "            break\n",
    "\n",
    "        couleur = detecter_couleur(frame)\n",
    "        print(f\"Couleur détectée : {couleur}\")\n",
    "\n",
    "        if couleur in POSITIONS:\n",
    "            couleur_trouvee = couleur\n",
    "            break  # Sortie anticipée si couleur détectée\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    if couleur_trouvee:\n",
    "        print(f\"Traitement de la couleur {couleur_trouvee}...\")\n",
    "        positions_cibles = POSITIONS[couleur_trouvee]\n",
    "        \n",
    "        # 1. Tourner vers la position du bac\n",
    "        poppy.abs_z.goto_position(positions_cibles[\"abs_z\"], duration=2, wait=True)\n",
    "\n",
    "        # 2. Déplacer le bras pour déposer l'objet\n",
    "        for motor_name, angle in positions_cibles.items():\n",
    "            if motor_name != \"abs_z\":\n",
    "                motor = getattr(poppy, motor_name)\n",
    "                motor.goto_position(angle, duration=2, wait=True)\n",
    "\n",
    "        # 3. Revenir à la position initiale\n",
    "        poppy.abs_z.goto_position(0, duration=2, wait=True)\n",
    "        poppy.r_shoulder_y.goto_position(0, duration=2, wait=True)\n",
    "        poppy.r_shoulder_x.goto_position(0, duration=2, wait=True)\n",
    "        poppy.r_elbow_y.goto_position(0, duration=2, wait=True)\n",
    "    else:\n",
    "        print(\"Aucune couleur détectée après 10 secondes. Arrêt du programme.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    poppy.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5 Assistants vocaux**\n",
    "- **Assistants disponibles** :\n",
    "  - **OpenAI GPT-3.5** : Intégration avec l'API OpenAI pour des réponses génératives.\n",
    "  - **Mistral-7B** : Modèle local via `transformers` pour des réponses hors ligne.\n",
    "- **Fonctionnalités** :\n",
    "  - Activation par mot-clé (\"Poppy\").\n",
    "  - Synthèse vocale avec `gTTS`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vosk (modèle local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import speech_recognition as sr\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import pyaudio\n",
    "import pyttsx3\n",
    "from pypot.creatures import PoppyTorso\n",
    "import os\n",
    "\n",
    "# Configuration Vosk\n",
    "MODEL_PATH = os.path.join(os.path.dirname(__file__), \"vosk-model-small-fr-0.22\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(\"Téléchargez le modèle depuis https://alphacephei.com/vosk/models\")\n",
    "\n",
    "model = Model(MODEL_PATH)\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "robot = PoppyTorso(simulator='vrep')\n",
    "\n",
    "def écouter():\n",
    "    mic = pyaudio.PyAudio()\n",
    "    stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8192)\n",
    "    print(\"Parlez...\")\n",
    "    stream.start_stream()\n",
    "    while True:\n",
    "        data = stream.read(4096)\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            texte = recognizer.Result()[14:-3]\n",
    "            return texte\n",
    "\n",
    "def parler(texte):\n",
    "    engine.say(texte)\n",
    "    engine.runAndWait()\n",
    "\n",
    "while True:\n",
    "    commande = écouter()\n",
    "    print(\"Commande détectée :\", commande)\n",
    "    if \"poppy\" in commande.lower():\n",
    "        # Remplacez cette partie par votre logique locale (ex : règles prédéfinies)\n",
    "        reponse = \"Bonjour ! Je suis Poppy, votre assistant hors ligne.\"\n",
    "        parler(reponse)\n",
    "        \n",
    "        if \"danse\" in commande.lower():\n",
    "            robot.play_sync(\"danse_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import time\n",
    "\n",
    "#config initiale\n",
    "client= OpenAI(api_key =\"your-key\") #ajouter une clé api dans les variables d'environnement\n",
    "\n",
    "WAKE_WORD= \"poppy\" #mot d'activation\n",
    "Langue=\"fr\" #fr en francais, en pour anglais\n",
    "\n",
    "def ecouter_commande(): \n",
    "    \"\"\"ecouter et retranscrire la voix de l'utilisateur\"\"\"\n",
    "    recognizer=sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source: \n",
    "        print(\"ecoute...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try: \n",
    "        texte=recognizer.recognize_google(audio, language= Langue+ \"-FR\")\n",
    "        print(f\"vous:{texte}\")\n",
    "        return texte.lower()\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print('Service de reconnaissance vocale indisponible')\n",
    "        return \"\"\n",
    "\n",
    "def generer_reponse(prompt):\n",
    "    \"\"\"Genere une reponse avec chatgpt\"\"\"\n",
    "    try:\n",
    "        reponse=client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\":\"system\",\"content\":\"Vous êtes un assistant utile. Repondez de manière concise.\"},{\"role\":\"user\",\"content\":prompt}])\n",
    "        return response.choices[0].message['content'].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur: {str(e)}\"\n",
    "\n",
    "\n",
    "def parler(texte):\n",
    "    \"\"\"convertir le texte en parole\"\"\"\n",
    "    tts=gTTS (text=texte, lang = Langue, slow= False)\n",
    "    tts.save('response.mp3')\n",
    "    os.system(\"mpg321 response.mp3\" if os.name==\"posix\" else \"start response.mp3\")\n",
    "\n",
    "def assistant_vocal():\n",
    "    print(f\"Assistant prêt, Dites ' {WAKE_WORD} ' pour activer\")\n",
    "\n",
    "    while True:\n",
    "        texte=ecouter_commande()\n",
    "\n",
    "        if texte and WAKE_WORD in texte: \n",
    "            parler (\"Oui, comment puis-je vous aider\")\n",
    "            print(\"En ecoute\")\n",
    "            commande=ecouter_commande()\n",
    "\n",
    "            if commande:\n",
    "                response = generer_reponse(commande)\n",
    "                print(f\"IA:{response}\")\n",
    "                parler(response)\n",
    "\n",
    "            else:\n",
    "                parler (\"Je nai pas compris votre demande\")\n",
    "\n",
    "        elif texte and \"arrête\" in texte: \n",
    "            parler (\"Au revoir\")\n",
    "            break\n",
    "if __name__==\"__main__\":\n",
    "    assistant_vocal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Mistral-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import time\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "Mistral_API_KEY=\"your_key\"\n",
    "client=MistralClient(api_key=Mistral_API_KEY)\n",
    "\n",
    "#charger le modèle (7B paramètres)\n",
    "model_name=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer= AutoTokenizer.from_pretrained(model_name)\n",
    "model= AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "#creation pipeline de génération\n",
    "mistral_pipeline=pipeline(\"text generation\", model=model, tokenizer = tokenizer, max_new_tokens=256, temparature=0.7)\n",
    "\n",
    "WAKE_WORD= \"poppy\" #mot d'activation\n",
    "Langue=\"fr\" #fr en francais, en pour anglais\n",
    "\n",
    "def ecouter_commande(): \n",
    "    \"\"\"ecouter et retranscrire la voix de l'utilisateur\"\"\"\n",
    "    recognizer=sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source: \n",
    "        print(\"ecoute...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try: \n",
    "        texte=recognizer.recognize_google(audio, language= Langue+ \"-FR\")\n",
    "        print(f\"vous:{texte}\")\n",
    "        return texte.lower()\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print('Service de reconnaissance vocale indisponible')\n",
    "        return \"\"\n",
    "\n",
    "def generer_reponse(prompt):\n",
    "    \"\"\"Genere une reponse avec Mistral\"\"\"\n",
    "    system_prompt=\"<s> [INST] Vous êtes un assistant utile. Repondez en français de manière concise. [/INST]\"\n",
    "    full_prompt=f\"{system_prompt}{prompt}</s>\"\n",
    "    try:\n",
    "        reponse=mistral_pipeline(\n",
    "            full_prompt,pad_token_id=tokenizer.eos_token_id)[0]['generated_text']\n",
    "            \n",
    "        return response.split(\"</s>\")[-1].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erreur: {str(e)}\"\n",
    "\n",
    "\n",
    "def parler(texte):\n",
    "    \"\"\"convertir le texte en parole\"\"\"\n",
    "    tts=gTTS (text=texte, lang = Langue, slow= False)\n",
    "    tts.save('response.mp3')\n",
    "    os.system(\"mpg321 response.mp3\" if os.name==\"posix\" else \"start response.mp3\")\n",
    "\n",
    "def assistant_vocal():\n",
    "    print(f\"Assistant Mistral prêt, Dites ' {WAKE_WORD} ' pour activer\")\n",
    "\n",
    "    while True:\n",
    "        texte=ecouter_commande()\n",
    "\n",
    "        if texte and WAKE_WORD in texte: \n",
    "            parler (\"Oui, comment puis-je vous aider\")\n",
    "            print(\"En ecoute\")\n",
    "            commande=ecouter_commande()\n",
    "\n",
    "            if commande:\n",
    "                response = generer_reponse(commande)\n",
    "                print(f\"Mistral:{response}\")\n",
    "                parler(response)\n",
    "\n",
    "            else:\n",
    "                parler (\"Je nai pas compris votre demande\")\n",
    "\n",
    "        elif texte and \"arrête\" in texte: \n",
    "            parler (\"Au revoir\")\n",
    "            break\n",
    "if __name__==\"__main__\":\n",
    "    assistant_vocal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
